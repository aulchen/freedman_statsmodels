\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\newenvironment{proof}{\paragraph{Proof:}}{\hfill$\square$}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\usepackage{graphicx}
\graphicspath{ {./images/Chapter04/} }

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\F}{\mathcal{F}}

\newcommand{\prob}{\boldsymbol{P}}
\newcommand{\E}{\text{E}}
\newcommand{\var}{\text{Var}}
\newcommand{\cov}{\text{Cov}}
\newcommand{\corr}{\text{Corr}}
\newcommand{\sd}{\text{SD}}
\newcommand{\se}{\text{SE}}

\newcommand{\pois}{\text{Pois}}

\author{Arthur Chen}
\title{Chapter 4 Multiple Regression}
\date{\today}

\begin{document}

\maketitle

\section*{Exercise Set A}

\subsection*{Problem 7}

Yule's regression model for pauperism:

\[
\Delta Paup = a + b \times \Delta Out + c \times \Delta Old + d \times \Delta Pop + error
\]

can be translated into matrix notation: $Y = X\beta + \epsilon$. We assume that $Y_i$ are the observed values of $X\beta + \epsilon$, that the $\epsilon_i$ are iid with mean zero and variance $\sigma^2$, and that $\epsilon$ is independent of $X$. For the metropolitan unions and the period 1871-81:

\subsubsection*{Part a}

What are $X$ and $Y$?

Take all of the entries of Table 1.3 and subtract 100 from them. $Y$ is the column vector of Paup, and $X$ is the columns Out, Old, and Pop, with a column of all 1's added on. (I will assume that the 1's column is added to the left of the $X$'s.)

\subsubsection*{Part b}

What are the observed values of $X_{41}$? $X_{42}$? $Y_4$?

$X_{41} = 1$, since that's the column of all ones. $X_{42}$ is the Out ratio for Chelsea, which is $21-100 = -79$. $Y_4$ is the Pauper for Chelsea, which is $64-100 = -36$.

\subsubsection*{Part c}

Where do we look in $(X'X)^{-1}X'Y$ to find the estimated coefficient of $\Delta Out$?

In the second entry, since the Out column is right after the Intercept column.

\section*{Problem Set B}

\subsection*{Problem 14}

We have from the equations in Chapter 2 that

\begin{align*}
\hat{a} &= \bar{y}-slope \bar{x} \\
\hat{b} &= corr(x, y)\frac{\sd(y)}{\sd(x)}
\end{align*}

In this case, $X$ is

\[
X = \begin{pmatrix}
1 & x_1 \\
1 & x_2 \\
\vdots & \vdots \\
1 & x_n
\end{pmatrix}
\]

so we get that

\[
X^TX = \begin{pmatrix}
n & \sum X_i \\
\sum X_i & \sum X_i^2
\end{pmatrix}
\]

We notice that

\[
\det(X^TX) = n\sum X_i - (\sum X_i)^2 = n^2 (\frac{1}{n} \sum X_i - \overline{X}^2) = n^2\var(X)
\]

and so

\[
(X^TX)^{-1} = \frac{1}{n^2 \var(X)} \begin{pmatrix}
\sum X_i^2 & -\sum X_i \\
- \sum X_i & n
\end{pmatrix}
\]

Multiplying out $X^TY$ gives

\[
X^TY = \begin{pmatrix}
\bar{Y} \\ \sum X_iY_i
\end{pmatrix}
\]

and so

\[
\hat{\beta} = \frac{1}{n^2 \var(X)} \begin{pmatrix}
\sum X_i^2 & -\sum X_i \\
- \sum X_i & n
\end{pmatrix}
\frac{1}{n^2 \var(X)} \begin{pmatrix}
\sum X_i^2 & -\sum X_i \\
- \sum X_i & n
\end{pmatrix}
\]

Calculating the coefficients,

\[
\hat{\beta}_2 = \frac{\frac{1}{n}\sum X_iY_i - \bar{x}\bar{y}}{\var{x}} = \frac{\cov(x, y)}{\var(x)}
= \frac{\corr(x, y)\sd(y)}{\sd(x)}
\]

which matches $\hat{b}$.

\end{document}